{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## @Author: ADD YOUR NAME HERE\r\n",
    "## @Date Created: ADD DATE CREATED\r\n",
    "## @Title: AI CHATBOT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing libraries and downloading packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Module for intents json file\r\n",
    "import json\r\n",
    "\r\n",
    "# Modules for Natural Language Processing\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "# Modules for Vectorization and Encoding\r\n",
    "import numpy as np\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "# Modules for Neural Networks\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout\r\n",
    "\r\n",
    "# Module for random responses\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# downloading model to tokenize messages\r\n",
    "nltk.download('punkt', quiet=True)\r\n",
    "# downloading stopwords\r\n",
    "nltk.download('stopwords', quiet=True)\r\n",
    "# downloading wordnet, which contains all lemmas of english language\r\n",
    "nltk.download('wordnet', quiet=True)\r\n",
    "\r\n",
    "stop_words = stopwords.words('english')\r\n",
    "stop_words"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function to clean the text\n",
    "\n",
    "### tokenizing, lemmatizing and removing stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "  A corpus is a collection of texts. This function is clean our corpus.\r\n",
    "    - lower all the words in the document\r\n",
    "    - tokenize the sentences\r\n",
    "    - remove all the stopwords\r\n",
    "    - lemmatize the words\r\n",
    "    - return the cleaned_corpus\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "def clean_corpus(corpus):\r\n",
    "  pass\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading and Cleaning our intents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corpus = []\r\n",
    "tags = []\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "    - Loading the json file of intents\r\n",
    "    - taking all the patterns of intents and appending it to corpus list\r\n",
    "    - and appending all tags of intents to tags list\r\n",
    "    - Cleaning the corpus list with our clean_corpus function\r\n",
    "    - These cleaned corpus will be used to build our neural network\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vectorizing the intents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    - Use the vectorizer to vectorize the cleaned courpus\r\n",
    "    - Encoding the tags and reshaping them using encoder\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "vectorizer = TfidfVectorizer()\r\n",
    "encoder = OneHotEncoder()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    Build a Neural Network with Sequential Model\r\n",
    "        - Use the Dense and Dropout Layers with the activation functions\r\n",
    "        - Compile the model with Adam Optimizer\r\n",
    "        - Fitting the model with 20 epochs\r\n",
    "\"\"\"\r\n",
    "model = Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying messages to intents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    Predicting the intent tag\r\n",
    "    - Use the trained model and predict the tag of particular message\r\n",
    "    - Tranform the message with vectorizer and inverse transform with the encoder and do the prediction\r\n",
    "    - Return the tag\r\n",
    "\"\"\"\r\n",
    "def predict_intent_tag(message):\r\n",
    "    pass\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "    Checking the intent_tag by giving a particular message from intents as an example\r\n",
    "\"\"\"\r\n",
    "# print(predict_intent_tag('Hello'))\r\n",
    "# print(predict_intent_tag('Tell me a joke'))\r\n",
    "# print(predict_intent_tag('What is your name?'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    Getting the complete intent with particular tag\r\n",
    "    - Matching the given tag with the tag in intents json file\r\n",
    "    - Returning the intent corresponding to the tag\r\n",
    "\"\"\"\r\n",
    "def get_intent(tag):\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Complete Working Chatbot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "    Make a while loop till the condition is True\r\n",
    "    - Take the input message user wants to send\r\n",
    "    - Predict the tag of the message using trained neural network\r\n",
    "    - Getting the complete intent from the predicted tag\r\n",
    "    - Generating random responses from intent\r\n",
    "    - Printing the Bot's Response\r\n",
    "    - Breaking the loop at a condition (Example -> if the predicted tag is goodbye or anything)\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "while True:\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}